# Scanntech RAG System - ISLR Technical Assistant

![Banner](https://img.shields.io/badge/Status-Completed-success) ![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![Stack](https://img.shields.io/badge/Stack-Llama3%20%7C%20LangChain%20%7C%20Streamlit-orange) ![RAGAS](https://img.shields.io/badge/Evaluation-RAGAS-red)

> **Repositorio oficial para el Scanntech AI Engineer Challenge.**

## ğŸš€ Executive Summary

Este proyecto implementa un ecosistema **RAG (Retrieval-Augmented Generation)** de nivel industrial diseÃ±ado para transformar el libro *"An Introduction to Statistical Learning" (ISL)* en un asistente tÃ©cnico interactivo y auditable.

A diferencia de un chat bÃ¡sico con PDFs, este sistema integra principios de ingenierÃ­a de software robusta:

* **Semantic Re-ranking & XAI:** ImplementaciÃ³n de una arquitectura de recuperaciÃ³n en dos pasos (Bi-Encoder + Cross-Encoder `ms-marco`). Esto asegura que solo el contexto de alta calidad llegue al LLM. AdemÃ¡s, la interfaz incluye herramientas de **Explicabilidad (XAI)** para que el usuario audite quÃ© fragmentos del libro se utilizaron.
* **Automated Evaluation Framework:** IntegraciÃ³n nativa de **RAGAS** utilizando **Llama 3.1 (8B)** como juez local. El sistema se auto-evalÃºa continuamente en mÃ©tricas de *Fidelidad*, *Relevancia*, *PrecisiÃ³n de Contexto* y *Recall*.
* **Unified Ecosystem:** Un orquestador central (`main.py`) gestiona el ciclo de vida completo: desde la ingesta ETL jerÃ¡rquica hasta la evaluaciÃ³n y el despliegue de la interfaz de usuario.

---

## ğŸ“¸ Visual Showcase

### 1. The Orchestrator (CLI)
GestiÃ³n centralizada del pipeline de datos y evaluaciÃ³n.
![MenÃº Principal CLI](assets/cli_menu.png)

### 2. User Interface & Observability
Dashboard interactivo con mÃ©tricas de RAGAS en tiempo real y transparencia de contexto.
![Streamlit Dashboard](assets/dashboard_ui.png)

### 3. Performance Metrics
Resultados del benchmark maestro evaluado sobre el *Ground Truth* del libro.
![MÃ©tricas RAGAS](assets/ragas_metrics.png)

---

## ğŸ—ï¸ Arquitectura TÃ©cnica (Free Style Presentation)

El sistema supera los retos tradicionales de los RAGs (alucinaciones y pÃ©rdida de contexto) mediante tres pilares:

### 1. Ingesta JerÃ¡rquica (`ingestion.py`)
No se limita a cortar texto. Utiliza `PyMuPDF4LLM` y anÃ¡lisis de TOC (Tabla de Contenidos) para:
* **Limpieza de Ruido:** Elimina Ã­ndices, bibliografÃ­as y encabezados repetitivos.
* **Metadatos Estructurales:** Cada vector estÃ¡ etiquetado con su `CapÃ­tulo`, `SubcapÃ­tulo` y `SecciÃ³n` exacta.
* **PreservaciÃ³n MatemÃ¡tica:** Detecta y formatea ecuaciones en LaTeX/Markdown para que no se pierda la lÃ³gica estadÃ­stica.

### 2. RecuperaciÃ³n HÃ­brida ("Two-Pass Retrieval")
* **Paso 1 (Broad):** BÃºsqueda vectorial con `nomic-ai/nomic-embed-text-v1.5` (Top-15). Este modelo de alta densidad (Matryoshka) permite una recuperaciÃ³n semÃ¡ntica superior.
* **Paso 2 (Deep):** Re-ranking con Cross-Encoder `ms-marco-MiniLM-L-6-v2`. Se aplica un umbral estricto (`score > -3.5`) para filtrar ruido.

### 3. EvaluaciÃ³n Sanitizada (`evaluator.py`)
Se descubriÃ³ que los modelos jueces pequeÃ±os (8B) fallan al evaluar texto con mucho LaTeX. Se implementÃ³ un algoritmo de **SanitizaciÃ³n** que convierte fÃ³rmulas complejas en tokens `[MATH_BLOCK]` antes de pasar por el juez, elevando la fiabilidad de las mÃ©tricas.

---

## ğŸ› ï¸ Setup Guide

Sigue estos pasos para replicar el entorno en local.

### 1. Prerrequisitos y Matriz de Modelos
Este sistema combina inferencia local vÃ­a Ollama y modelos especializados de HuggingFace (configurados en `src/config.py`).

**Modelos Utilizados:**
* **Chat LLM:** `llama3.2:3b` (Optimizado para baja latencia en inferencia).
* **Judge LLM:** `llama3.1:8b` (Capacidad de razonamiento superior para evaluaciÃ³n RAGAS).
* **Embeddings:** `nomic-ai/nomic-embed-text-v1.5` (Gestionado por `langchain-huggingface`).

**InstalaciÃ³n de Motores:**
1.  Descarga e instala [Ollama](https://ollama.com).
2.  Descarga los modelos LLM requeridos:

```bash
# Modelo para el Chat
ollama pull llama3.2:3b

# Modelo Juez para RAGAS
ollama pull llama3.1:8b
```

*Nota: El modelo de embeddings (`nomic-embed-text-v1.5`) y el Cross-Encoder se descargarÃ¡n automÃ¡ticamente en la carpeta de cachÃ© de HuggingFace durante la primera ejecuciÃ³n de la ingesta.*

### 2. InstalaciÃ³n del Entorno

```bash
# 1. Clonar el repositorio
git clone <https://github.com/Joxhel/scanntech-rag-system>
cd scanntech-rag-system

# 2. Crear y activar entorno virtual (Recomendado)
python -m venv .venv
source .venv/bin/activate  # Mac/Linux
# .\.venv\Scriptsactivate # Windows PowerShell

# 3. Instalar dependencias
pip install -r requirements.txt
```

---

## âš¡ Execution Flow

El proyecto cuenta con un `main.py` que centraliza todas las operaciones.

### Paso 1: Iniciar el Orquestador
Ejecuta el siguiente comando en tu terminal:

```bash
python main.py
```

### Paso 2: Seleccionar OperaciÃ³n
VerÃ¡s un menÃº interactivo con las siguientes opciones:

1.  **ğŸ› ï¸ INGESTA:** Procesa el PDF `GenAI Challenge.pdf` y crea/actualiza la base de datos vectorial en `db/chroma_db_storage`.
    * *Nota: Se incluye una versiÃ³n pre-cargada de la DB en el repo para pruebas rÃ¡pidas.*
2.  **ğŸ“Š EVALUACIÃ“N:** Ejecuta el benchmark de RAGAS. Compara las respuestas del sistema contra el `ground_truth.json` y genera un reporte en CSV.
3.  **ğŸ’¬ CHAT:** Lanza automÃ¡ticamente la interfaz web de Streamlit.

### Alternativa: Lanzamiento Directo
Si ya tienes la base de datos y quieres ir directo al chat:

```bash
streamlit run app.py
```

---

## ğŸ“‚ Project Structure

```text
scanntech-rag-system/
â”œâ”€â”€ assets/             # ImÃ¡genes y evidencias para el README
â”œâ”€â”€ data/               # Documentos fuente (PDF del libro ISLR)
â”œâ”€â”€ db/                 # Persistencia de ChromaDB (Pre-cargada)
â”œâ”€â”€ eval/               
â”‚   â”œâ”€â”€ benchmark/      # Ground Truth (QA pairs) para evaluaciÃ³n
â”‚   â”œâ”€â”€ logs/           # Trazabilidad de interacciones (JSONL)
â”‚   â””â”€â”€ reports/        # GrÃ¡ficos y CSV generados por RAGAS
â”œâ”€â”€ src/                
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py       # Single Source of Truth (Rutas, Modelos, ConfiguraciÃ³n)
â”‚   â”œâ”€â”€ ingestion.py    # Pipeline ETL (Limpieza, TOC Hierarchy, IndexaciÃ³n)
â”‚   â”œâ”€â”€ query_rag.py    # Motor RAG (Retrieval + Re-ranker + Chain of Verification)
â”‚   â””â”€â”€ evaluator.py    # LÃ³gica de mÃ©tricas RAGAS con sanitizaciÃ³n de texto
â”œâ”€â”€ app.py              # Interfaz de Usuario (Streamlit Dashboard)
â”œâ”€â”€ main.py             # CLI Entrypoint (Orquestador)
â”œâ”€â”€ requirements.txt    # Dependencias del proyecto
â””â”€â”€ README.md           # DocumentaciÃ³n oficial
```

---

## ğŸ›¡ï¸ License & Contact

Desarrollado por **Jose Luis Cabrera Vega** para el proceso de selecciÃ³n de **Scanntech**.
