# Scanntech RAG System - ISLR Technical Assistant

![Banner](https://img.shields.io/badge/Status-Completed-success) ![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![Stack](https://img.shields.io/badge/Stack-Llama3%20%7C%20LangChain%20%7C%20Streamlit-orange) ![RAGAS](https://img.shields.io/badge/Evaluation-RAGAS-red)

> **Repositorio oficial desarrollado para el Scanntech AI Engineer Challenge.**

## üöÄ Resumen del Proyecto

Este sistema transforma el libro *"An Introduction to Statistical Learning" (ISL)* en un asistente t√©cnico inteligente. El objetivo principal fue construir un ecosistema que no solo responda preguntas t√©cnicas con precisi√≥n, sino que ofrezca **transparencia total** sobre las fuentes consultadas y mantenga un **control de calidad riguroso** mediante m√©tricas automatizadas.

A lo largo del desarrollo, implement√© una arquitectura basada en tres pilares:
* **Recuperaci√≥n Sem√°ntica Avanzada:** Uso de un flujo de dos pasos (Retrieval + Re-ranking) para asegurar que el modelo trabaje solo con la informaci√≥n m√°s pertinente.
* **Observabilidad en Tiempo Real:** Integraci√≥n de un panel de m√©tricas RAGAS directamente en la interfaz para monitorear la salud del sistema.
* **Ingesta con Preservaci√≥n T√©cnica:** Enfoque en la extracci√≥n limpia de f√≥rmulas matem√°ticas y estructuras jer√°rquicas del PDF original.

---

## üì∏ Evidencias del Sistema (Visual Showcase)

### 1. El Orquestador Central (CLI)
Desarroll√© un punto de entrada √∫nico (`main.py`) que permite gestionar todo el ciclo de vida del dato: desde la ingesta inicial hasta la ejecuci√≥n de benchmarks de evaluaci√≥n.
![Men√∫ Principal CLI](assets/cli_menu.png)

### 2. Dashboard de Usuario y Observabilidad
La interfaz en Streamlit prioriza la experiencia del usuario. El panel lateral muestra los promedios hist√≥ricos de las m√©tricas de calidad, permitiendo validar la confianza del sistema antes de iniciar el chat.
![Streamlit Dashboard](assets/sidebar_observability.gif)

### 3. Rendimiento y M√©tricas RAGAS
El sistema genera reportes visuales y descriptivos tras cada evaluaci√≥n. Adem√°s de los benchmarks, el sistema es capaz de **analizar las interacciones reales de los usuarios almacenadas en logs**, calculando m√©tricas de fidelidad mediante una comparativa directa entre el contexto recuperado y la respuesta generada, asegurando una mejora continua basada en datos de uso real.
![M√©tricas de Rendimiento](assets/ragas_metrics.png)

---

## üèóÔ∏è Arquitectura y Preprocesamiento

El n√∫cleo del proyecto reside en c√≥mo se preparan y recuperan los datos t√©cnicos. Aqu√≠ detallo las decisiones clave en `src/ingestion.py`, `src/query_rag.py` y `src/evaluator.py`:

### 1. Ingesta Inteligente con PyMuPDF4LLM
Para manejar la complejidad del libro ISLR, utilic√© `PyMuPDF4LLM` combinado con l√≥gica personalizada para:
* **Extracci√≥n de F√≥rmulas y LaTeX:** A diferencia de otros extractores, este flujo preserva la sintaxis matem√°tica, permitiendo que el modelo comprenda las ecuaciones sin errores de caracteres extra√±os.
* **An√°lisis de Estructura Jer√°rquica:** El sistema mapea la Tabla de Contenidos (TOC) para inyectar metadatos de `Cap√≠tulo`, `Subcap√≠tulo` y `Secci√≥n` en cada fragmento.
* **Filtrado de Ruido Sem√°ntico:** Se implement√≥ una l√≥gica para **eliminar el √çndice Alfab√©tico y la Tabla de Contenidos** del cuerpo del texto indexado. Esto evita que el motor de b√∫squeda recupere listas de temas sin contenido explicativo, mejorando dr√°sticamente la precisi√≥n del contexto.
* **Limpieza Especializada:** Se eliminan ruidos de edici√≥n (DOIs, copyright) que suelen ensuciar los embeddings.

### 2. Recuperaci√≥n de Dos Pasos (Two-Pass Retrieval)
La recuperaci√≥n se dise√±√≥ en dos fases para garantizar la relevancia m√°xima del contexto:
* **B√∫squeda Vectorial (Broad Search):** Recuperaci√≥n inicial de 15 fragmentos usando `nomic-ai/nomic-embed-text-v1.5`.
* **Re-ranking Sem√°ntico (Deep Search):** Aplicaci√≥n de un **Cross-Encoder** (`ms-marco-MiniLM-L-6-v2`) para re-evaluar la relevancia de esos 15 fragmentos, filtrando cualquier contexto que no aporte valor real antes de enviarlo al LLM.
* **Umbral de Calidad:** Se aplica un filtro estricto de score. Si ning√∫n fragmento supera este umbral, el sistema declara que no tiene informaci√≥n suficiente antes de arriesgarse a alucinar.

### 4. Prompt Engineering y Generaci√≥n
El motor (`src/query_rag.py`) utiliza un protocolo de verificaci√≥n robusto:
* **Estructura XML:** Los fragmentos se inyectan en etiquetas `<DOCUMENT>` con metadatos de p√°gina y cap√≠tulo para evitar confusiones de contexto.
* **Thought Process (CoV):** El prompt obliga al modelo a razonar antes de responder (identificar conceptos, verificar presencia en fragmentos y emitir citaciones obligatorias `[Page X]`).
* **Temperatura 0:** Configurada para m√°xima consistencia y fidelidad t√©cnica (OllamaLLM).


### 3. Prompt Engineering y Generaci√≥n
El motor (`src/query_rag.py`) utiliza un protocolo de verificaci√≥n robusto:
* **Estructura XML:** Los fragmentos se inyectan en etiquetas `<DOCUMENT>` con metadatos de p√°gina y cap√≠tulo para evitar confusiones de contexto.
* **Thought Process (CoV):** El prompt obliga al modelo a razonar antes de responder (identificar conceptos, verificar presencia en fragmentos y emitir citaciones obligatorias `[Page X]`).
* **Temperatura 0:** Configurada para m√°xima consistencia y fidelidad t√©cnica (OllamaLLM).

### 4. Evaluaci√≥n (RAGAS Framework)
Para garantizar la fiabilidad de las m√©tricas de **RAGAS**, implement√© un flujo de evaluaci√≥n:
* **Juez Especializado:** Se utiliza `llama3.1:8b` como juez evaluador por su capacidad superior para seguir instrucciones complejas en comparaci√≥n con modelos m√°s peque√±os.
* **Sanitizaci√≥n de Datos:** Desarroll√© una l√≥gica que convierte bloques de c√≥digo y f√≥rmulas complejas en tokens simplificados (`[MATH_BLOCK]`) antes de la evaluaci√≥n. Esto evita que el juez se distraiga con la sintaxis de LaTeX y se enfoque puramente en la fidelidad sem√°ntica de la respuesta.
* **M√©tricas Core:** El sistema mide continuamente *Faithfulness*, *Answer Relevancy*, *Context Precision* y *Context Recall*.

Se ejecut√≥ un benchmark maestro sobre preguntas t√©cnicas donde:

| M√©trica | Resultado | Justificaci√≥n T√©cnica |
| :--- | :--- | :--- |
| **Faithfulness** | **0.76** | Representa la capacidad del modelo para mantenerse fiel al contexto recuperado sin alucinar. |
| **Answer Relevancy** | **0.86** | Indica qu√© tan directa y √∫til es la respuesta para la consulta del usuario. |
| **Context Precision** | **0.87** | El Re-ranker posiciona los mejores datos en los primeros lugares de forma efectiva. |
| **Context Recall** | **0.81** | El sistema localiza la informaci√≥n necesaria en el 81% de los casos complejos del benchmark. |

---

## üì∫ Demos de Interacci√≥n

### Interacci√≥n T√©cnica
El asistente explica conceptos estad√≠sticos complejos citando la ubicaci√≥n exacta en el libro para su verificaci√≥n.
![Demo Pregunta V√°lida](assets/valid_query_demo.gif)

### Manejo de Preguntas Fuera de Dominio
El sistema identifica consultas que no pertenecen al dominio del libro (como cultura general), evitando alucinaciones y manteniendo el enfoque t√©cnico.
![Demo Pregunta Inv√°lida](assets/invalid_query_demo.gif)

---

## üõ†Ô∏è Gu√≠a de Instalaci√≥n y Setup

### 1. Modelos de IA (Ollama)
Este sistema utiliza **Ollama** para la inferencia local. Aseg√∫rate de tener instalados los siguientes modelos:
```bash
ollama pull llama3.2:3b  # Para el Chat (Velocidad)
ollama pull llama3.1:8b  # Para el Juez Evaluador (Razonamiento)
```

### 2. Entorno y Dependencias
El proyecto utiliza un archivo `requirements.txt` con versiones fijas para garantizar la reproducibilidad del entorno.
```bash
# Crear y activar ambiente (Recomendado Python 3.10 o 3.11)
python -m venv .venv
source .venv/bin/activate  # O .\\.venv\\Scripts\\activate en Windows

# Actualizar pip e instalar dependencias fijas
pip install --upgrade pip
pip install -r requirements.txt
```

---

## üìÇ Project Structure

```text
scanntech-rag-system/
‚îú‚îÄ‚îÄ assets/             # Im√°genes y evidencias para el README
‚îú‚îÄ‚îÄ data/               # Documentos fuente (PDF del libro ISLR)
‚îú‚îÄ‚îÄ db/                 # Persistencia de ChromaDB (Pre-cargada)
‚îú‚îÄ‚îÄ eval/               
‚îÇ   ‚îú‚îÄ‚îÄ benchmark/      # Ground Truth (QA pairs) para evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ logs/           # Trazabilidad de interacciones (JSONL)
‚îÇ   ‚îî‚îÄ‚îÄ reports/        # Gr√°ficos y CSV generados por RAGAS
‚îú‚îÄ‚îÄ src/                
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py       # Single Source of Truth (Rutas, Modelos, Configuraci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py    # Pipeline ETL (Limpieza, TOC Hierarchy, Indexaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ query_rag.py    # Motor RAG (Retrieval + Re-ranker + Chain of Verification)
‚îÇ   ‚îî‚îÄ‚îÄ evaluator.py    # L√≥gica de m√©tricas RAGAS con sanitizaci√≥n de texto
‚îú‚îÄ‚îÄ app.py              # Interfaz de Usuario (Streamlit Dashboard)
‚îú‚îÄ‚îÄ main.py             # CLI Entrypoint (Orquestador)
‚îú‚îÄ‚îÄ requirements.txt    # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md           # Documentaci√≥n oficial
```

---

## ‚ö° Execution Flow

El proyecto cuenta con un `main.py` que centraliza todas las operaciones.

### Paso 1: Iniciar el Orquestador
Ejecuta el siguiente comando en tu terminal:

```bash
python main.py
```

### Paso 2: Seleccionar Operaci√≥n
Ver√°s un men√∫ interactivo con las siguientes opciones:

1. **üõ†Ô∏è INGESTA:** Procesa el PDF `GenAI Challenge.pdf` y crea/actualiza la base de datos vectorial en `db/chroma_db_storage`.
    * *Nota: Se incluye una versi√≥n pre-cargada de la DB en el repo para pruebas r√°pidas.*
2. **üìä EVALUACI√ìN:** Ejecuta el benchmark de RAGAS. Compara las respuestas del sistema contra el `ground_truth.json` y genera un reporte en CSV.
3. **üí¨ CHAT:** Lanza autom√°ticamente la interfaz web de Streamlit.


### Alternativa: Lanzamiento Directo
Si ya tienes la base de datos y quieres ir directo al chat:

```bash
streamlit run app.py
```

---
## üöÄ Trabajo Futuro y Escalabilidad (Roadmap)

Para evolucionar este sistema hacia un entorno de producci√≥n de alta disponibilidad, se proponen las siguientes mejoras estrat√©gicas:

1. **Optimizaci√≥n de Recuperaci√≥n (Query Transformation):**
   * **Query Rewriting:** Implementar un paso previo donde un LLM interprete y limpie la intenci√≥n del usuario antes de la consulta vectorial.
   * **HyDE (Hypothetical Document Embeddings):** Generar respuestas hipot√©ticas para capturar fragmentos sem√°nticamente similares con mayor precisi√≥n.

2. **Arquitectura GraphRAG:**
   * Migrar a una base de datos de grafos (**Neo4j**) para conectar conceptos transversales del libro que no est√°n cerca f√≠sicamente (ej. relacionar t√©cnicas de *Regularizaci√≥n* en el Cap. 6 con su aplicaci√≥n en *SVM* en el Cap. 9).

3. **Transici√≥n a Modelos Cloud:**
   * Integraci√≥n opcional mediante API con **Gemini 1.5 Pro** o **GPT-4o** para consultas de "borde" que requieran un razonamiento matem√°tico extremo o s√≠ntesis de m√∫ltiples cap√≠tulos.

4. **Refinamiento de Inferencia Local (Prompt Tuning):**
   * Ajustar iterativamente el `Prompt Template` utilizado en `OllamaLLM` para optimizar el uso de la ventana de contexto y mejorar la asimilaci√≥n de instrucciones de formato espec√≠ficas del dominio estad√≠stico.
---
## üõ°Ô∏è License & Contact

Desarrollado por [**Jose Luis Cabrera Vega**](https://www.linkedin.com/in/josecabrerav) para el proceso de selecci√≥n de **Scanntech**.

